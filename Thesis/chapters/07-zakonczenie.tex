\chapter{Uwagi końcowe}

\noindent Celem niniejszej pracy było zaproponowanie nowych algorytmów przetwarzania strumieniowego, które poradziłyby sobie z nauką na niezbalansowanych i zmiennych strumieniach danych. Do tej pory w literaturze najczęściej analizowaną zmianą w strumieniu była zmiana globalnego współczynnika niezbalansowania (\english{global imbalance ratio}). Kilku badaczy w swoich pracach wykazało jednak, że inne czynniki takie jak np. podział grupy przykładów z klasy mniejszościowej na kilka mniejszych grup czy napływ przypadków określonego typu, mogą być znacznie bardziej wpływowe na jakość klasyfikacji aniżeli zmiana współczynnika niezbalansowania. Wobec tego faktu stworzone algorytmy zostały przetestowane na wygenerowanych strumieniach danych z określonym typem zmiany w celu określenia jak dany klasyfikator radzi sobie z określonym typem zmiany.

W ramach pracy zaproponowano trzy nowe algorytmy odpowiedzalne za klasyfikację niezbalansowanych i zmiennych strumieni danych. Pierwsze z podejść to algorytm \textit{Neighbourhood Oversampling Online Bagging}, którego główną ideą jest modyfikacja parametru $\lambda$ rozkładu Poissona dla przykładów z klasy mniejszościowej. Przy wyznaczaniu tego parametru brane pod uwagę są dwa czynniki: liczność przykładów w każdej z klas w danym momencie w czasie oraz analiza najbliższego sąsiedztwa dla określonego przykładu. Drugim z podejść był algorytm \textit{Neighbourhood Undersampling Online Bagging}, którego idea jest bardzo podobna jak w przypadku poprzednika, z tą różnicą, że modyfikacja parametru $\lambda$ rozkładu Poissona dokonywana jest dla przykładów z klasy większościowej. Ostatnim z podejść jest algorytm \textit{Hybrid Neighbourhood Online Bagging}, który w swoim działaniu wykorzystuje jako klasyfikatory składowe algorytmy \textit{NOOB} oraz \textit{NUOB}. Predykcja dla tego podejścia odbywa się według algorytmu, który w danej chwili ma wyższą wartość miary \textit{G-mean}.

W dalszej części przeprowadzono ocenę eksperymentalną dla klasyfikatorów opisanych w poprzednim akapicie oraz dla algorytmów znanych z literatury, takich jak: \textit{Online Bagging}, \textit{Oversampling Online Bagging}, \textit{Undersampling Online Bagging}. Przeprowadzona analiza wykazała, że dla strumieni danych z jednym czynnikiem trudności zaprezentowane rozszerzenia nie spisują się dużo lepiej od podejść znanych z literatury, co wykazały wyniki testów statystycznych zaprezentowanych w tabeli \ref{Tab:SingleDriftFriedman}. Pod kątem miary \textit{G-mean} najlepszym w rankingu okazał się być algorytm \textit{OOB}. Wynik ten nie jest oczekiwaną obserwacją, przez co pozostawia możliwości do dalszej pracy nad zaproponowanymi algorytmami w celu ich poprawy. Kolejna część analizy wykazała, że nowe podejścia \textit{NUOB} oraz \textit{NOOB} radzą sobie szczególnie dobrze dla złożonych strumieni danych, które posiadają przynajmniej dwa czynniki trudności. Stworzone na podstawie testów statystycznych rankingi pokazały, że wyniki generowane przez zaproponowane algorytmy są statystycznie istotne w porównaniu do pozostałych algorytmów - szczególnie widoczne różnice zostały zaobserwowane w przypadku analizy par \textit{Imbalance+Borderline}, \textit{Imbalance+Rare} oraz \textit{Split+Rare}. Dla algorytmu hybrydowego można zaobserwować, że był on jednym z trzech najbardziej istotnych algorytmów (obok \textit{OOB} oraz \textit{NUOB}) pod kątem analizy strumieni danych z jednym czynnikiem trudności dla miary \textit{G-mean}. Sytuacja ta, podobnie jak dla algorytmów \textit{NUOB} oraz \textit{NOOB}, zmienia się przy analizie wyników bardziej złożonych strumieni danych. W przypadku strumieni dotyczących par czynników trudności algorytm hybrydowy okazał się zająć pierwsze miejsce w utworzonych rankingach dla miary \textit{G-mean} oraz \textit{Recall} - dla każdej z analizowanych par wynik algorytmu \textit{HNOB} okazał się być statystycznie istotny.

Mimo że zaproponowane podejścia charakteryzują się poprawą jakości klasyfikacji pod kątem analizowanych miar \textit{G-mean} oraz \textit{Recall}, to nadal widoczne jest miejsce do poprawy aktualnie osiąganych wyników. Szczególnie największy spadek jakości klasyfikacji widoczny jest dla strumieni danych zawierających w swoim dryfie napływ przykładów typu \textit{Rare}. Obserwacja ta otwiera pole do działania dla przyszłych badaczy zajmujących się tematyką niezbalansowanych i zmiennych strumieni danych. Warto także zwrócić uwagę na fakt, że zaproponowane podejścia wykazują się największymi różnicami w stosunku do pozostałych algorytmów, gdy analizowany scenariusz zawiera wzrost przypadków typu \textit{Rare}. Wobec tej obserwacji otwiera się dalsze pole do pracy nad rozszerzeniami, które w swoim działaniu skupiałyby się na poprawie trafności klasyfikacji dla strumieni nie zawierających zmian dotyczących wzrostu liczności przypadków rzadkich. Zaproponowane w tej pracy podejścia charakteryzowały się wynikami mocno zbliżonymi do porównywanych algorytmów - widoczne jest to przykładowo dla par \textit{Imbalance+Move} lub \textit{Imbalance+Merge}.

Jedną z modyfikacji, która mogłaby przynieść poprawę wyników, a której nie zdołano przetestować w niniejszej pracy, jest skorzystanie z algorytmu bazującego na detektorze dryfu, np. \textit{DDM} lub \textit{EDDM} wraz z wprowadzeniem buforów odpowiedzialnych za przechowywanie określonych typów przykładów. W ten sposób, poprzez analizę najbliższego sąsiedztwa danego elementu, byłoby możliwe zebranie przykładów trudnych do nauki, które następnie mogłyby być wykorzystane do stworzenia nowego klasyfikatora po przekroczeniu poziomu alarmu przez dotychczasowy model. Wraz z osiągnięciem poziomu alarmu Podejście to pozwoliłoby na szersze spojrzenie pod kątem analizy określonych typów przykładów przez algorytmy przetwarzania strumieniowego.