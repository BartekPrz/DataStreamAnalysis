\chapter{Uwagi końcowe}

\noindent Celem niniejszej pracy było zaproponowanie nowych algorytmów przetwarzania strumieniowego, które poradziłyby sobie z nauką na niezbalansowanych i zmiennych strumieniach danych. Do tej pory w literaturze najczęściej analizowaną zmianą w strumieniu była zmiana globalnego współczynnika niezbalansowania (\english{global imbalance ratio}). Kilku badaczy w swoich pracach wykazało jednak, że inne czynniki takie jak np. podział grupy przykładów z klasy mniejszościowej na kilka mniejszych grup czy napływ przypadków określonego typu, mogą być znacznie bardziej wpływowe na trafność klasyfikacji aniżeli zmiana współczynnika niezbalansowania. Wobec tego faktu stworzone algorytmy zostały przetestowane na specjalnie wygenerowanych strumieniach danych w celu określenia jak dany klasyfikator radzi sobie z określonym typem zmiany.

W ramach pracy zaproponowano trzy nowe algorytmy odpowiedzalne za klasyfikację niezbalansowanych i zmiennych strumieni danych. Pierwsze z podejść to algorytm \textit{Neighbourhood Oversampling Online Bagging}, którego główną ideą jest modyfikacja parametru $\lambda$ rozkładu Poissona dla przykładów z klasy mniejszościowej. Przy wyznaczaniu tego parametru brane pod uwagę są dwa czynniki: liczność przykładów w każdej z klas w danym momencie w czasie oraz analiza najbliższego sąsiedztwa dla określonego przykładu. Drugim z podejść był algorytm \textit{Neighbourhood Undersampling Online Bagging}, którego idea jest bardzo podobna jak w przypadku poprzednika, z tą różnicą, że modyfikacja parametru $\lambda$ rozkładu Poissona dokonywana jest dla przykładów z klasy większościowej. Ostatnim z podejść jest algorytm \textit{Hybrid Neighbourhood Online Bagging}, który w swoim działaniu wykorzystuje jako klasyfikatory składowe algorytmy \textit{NOOB} oraz \textit{NUOB}. Predykcja dla tego podejścia odbywa się według algorytmu, który w danej chwili ma wyższą wartość miary \textit{G-mean}.

W dalszej części przeprowadzono ocenę eksperymentalną dla klasyfikatorów opisanych w poprzednim akapicie oraz dla algorytmów znanych z literatury, takich jak: \textit{Online Bagging}, \textit{Oversampling Online Bagging}, \textit{Undersampling Online Bagging}. Przeprowadzona analiza wykazała, że dla strumieni danych z jednym czynnikiem trudności zaprezentowane rozszerzenia nie spisują się dużo lepiej od podejść znanych z literatury, co wykazały wyniki testów statystycznych zaprezentowanych w tabeli \ref{Tab:SingleDriftFriedman}. Pod kątem miary \textit{G-mean} najlepszym w rankingu okazał się być algorytm \textit{OOB}. Wynik ten nie jest oczekiwaną obserwacją, przez co pozostawia możliwości do dalszej pracy nad zaproponowanymi algorytmami w celu ich poprawy. Kolejna część analizy wykazała, że nowe podejścia \textit{NUOB} oraz \textit{NOOB} radzą sobie szczególnie dobrze dla złożonych strumieni danych, które posiadają przynajmniej dwa czynniki trudności. Stworzone na podstawie testów statystycznych rankingi pokazały, że wyniki generowane przez zaproponowane algorytmy są wyraźnie lepsze w porównaniu do pozostałych algorytmów - szczególnie widoczne różnice zostały zaobserwowane w przypadku analizy par \textit{Imbalance+Borderline}, \textit{Imbalance+Rare} oraz \textit{Split+Rare}. Dla algorytmu hybrydowego można zaobserwować, że był on jednym z trzech najbardziej istotnych algorytmów (obok \textit{OOB} oraz \textit{NUOB}) pod kątem analizy strumieni danych z jednym czynnikiem trudności dla miary \textit{G-mean}. Sytuacja ta, podobnie jak dla algorytmów \textit{NUOB} oraz \textit{NOOB}, zmienia się przy analizie wyników bardziej złożonych strumieni danych. W przypadku strumieni dotyczących par czynników trudności algorytm hybrydowy okazał się zająć pierwsze miejsce w utworzonych rankingach dla miary \textit{G-mean} oraz \textit{Recall} - dla każdej z analizowanych par wynik algorytmu \textit{HNOB} okazał się być statystycznie istotny. Podejście hybrydowe także radziło sobie dobrze podczas klasyfikacji strumieni danych z więcej niż dwoma czynnikami trudności, co potwierdzają wyniki eksperymentów oraz testy statystyczne przedstawione w sekcji \ref{Label:ComplexScenariosHNOB}.

Mimo że zaproponowane podejścia charakteryzują się poprawą trafności klasyfikacji pod kątem analizowanych miar \textit{G-mean} oraz \textit{Recall}, to nadal widoczne jest miejsce do poprawy aktualnie osiąganych wyników. Szczególnie największy spadek trafności klasyfikacji widoczny jest dla strumieni danych zawierających w swoim dryfie napływ przykładów typu \textit{Rare}. Obserwacja ta otwiera pole do działania dla przyszłych badaczy zajmujących się tematyką niezbalansowanych i zmiennych strumieni danych. Warto także zwrócić uwagę na fakt, że zaproponowane podejścia wykazują się największymi różnicami w stosunku do pozostałych algorytmów, gdy analizowany scenariusz zawiera wzrost przypadków typu \textit{Rare}. Taka okoliczność może być inspiracją do dalszych rozszerzeń, które w swoim działaniu skupiałyby się na poprawie trafności klasyfikacji dla strumieni nie zawierających zmian dotyczących wzrostu liczności przypadków rzadkich. Zaproponowane w tej pracy podejścia charakteryzowały się wynikami mocno zbliżonymi do porównywanych algorytmów dla określonych scenariuszy, np. \textit{Sub-cluster Merge} lub \textit{Imbalance+Move}, co wykazały przeprowadzone testy statystyczne, zawarte w tabelach \ref{Tab:SingleDriftFriedman} oraz \ref{Tab:DoubleDriftFriedman}.

Jedną z modyfikacji, która mogłaby przynieść poprawę wyników, a której nie zdołano przetestować w niniejszej pracy, jest skorzystanie z algorytmu bazującego na detektorze dryfu, np. \textit{DDM} lub \textit{EDDM} wraz z wprowadzeniem buforów odpowiedzialnych za przechowywanie określonych typów przykładów. W ten sposób, poprzez analizę najbliższego sąsiedztwa danego elementu, byłoby możliwe zebranie wszystkich przykładów trudnych do nauki, zawierających wyróżniającą się wiedzę o elementach z klasy mniejszościowej. Wraz ze zgłoszeniem, przez detektor dryfu, poziomu alarmu rozważano dwie możliwości dalszego działania. Pierwsza z możliwości odnosiła się do odrzucenia najsłabszego klasyfikatora składowego, pod kątem metryki \textit{G-mean}, ze zbioru klasyfikatorów składowych. Jego miejsce zająłby nowy klasyfikator bazowy nauczony na odpowiednich przykładach przechowywanych w buforach. Druga z możliwości dotyczyła porzucenia dotychczas wykorzystywanego klasyfikatora złożonego na rzecz nowo utworzonego modelu nauczonego na odpowiednich przykładach trzymanych w buforach. Zastosowanie takiego podejścia pozwoliłoby na jeszcze szersze spojrzenie pod kątem analizy określonych typów przykładów przez algorytmy przetwarzania strumieniowego.

\newpage\null\thispagestyle{empty}\newpage